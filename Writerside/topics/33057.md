# AI担忧日益加剧？OpenAI拟建新团队，以防范“灾难性风险”
**财联社**

**2023-10-27 06:01**

**https://news.futunn.com/post/33360746**

来源：财联社 作者：黄君芝

①OpenAI已经组建了一个名为“准备”（Preparedness）的团队； ②该小组将分析并试图防范人工智能系统潜在的“灾难性风险”； ③这些风险包括从网络安全问题到化学、核和生物威胁。

随着快速发展的人工智能技术越来越强大，OpenAI正在组建一个新的团队，旨在最大限度地降低人工智能带来的风险。

在周四发布的一篇博客文章中，这家以广受欢迎的聊天机器人ChatGPT而闻名的公司宣布，它已经组建了一个名为“准备”（Preparedness）的团队，由Aleksander Madry领导，他在麻省理工学院（MIT）担任教职期间一直在OpenAI工作。

![](https://postimg.futunn.com/16983728601556679722173.png)

据称，该小组将分析并试图防范人工智能系统潜在的“灾难性风险”，从网络安全问题到化学、核和生物威胁。

该团队还将制定一项政策，旨在帮助公司确定如何降低开发所谓的“前沿模型”可能带来的风险。“前沿模型”是指比目前普遍使用的人工智能技术更强大的下一代人工智能技术。

长期以来，OpenAI的目标一直集中在构建人工通用智能（AGI）上，即能够比人类更好地执行一系列任务的人工智能。虽然目前的人工智能系统不符合这一描述，但该公司表示，它需要“确保我们拥有高性能人工智能系统安全所需的理解和基础设施”。

在全球对人工智能快速发展的担忧日益加剧的情况下，此前Open AI首席执行官Sam Altman也不断重申监管AI技术的重要性，同时承认监管失误的可能性。

Altman表示，全球努力引入AI法规，例如英国计划在11月举办全球AI安全峰会。峰会旨在深入研究尖端人工智能技术带来的挑战，并探索加强国家和国际监管框架的方法。昨天，英国首相苏纳克就该峰会发表讲话。

他说，他认为禁止通用人工智能（AGI）不切实际且无法执行，并表示英国倾向于鼓励创。当被问及英国政府是否会监管人工智能，苏纳克回答说：“我认为出于多种原因，我们不应急于监管，如果你还不完全理解某件事，就很难对其监管。”

苏纳克表示，正确的顺序是加大投资，“比其他任何人都多”，以培养政府了解AI风险的能力，此时英国将对”应采取什么适当行动”有更深入的理解。

编辑/lambor